# ğŸ· Wine Quality Prediction - End-to-End ML Project

![Python](https://img.shields.io/badge/Python-3.10-blue.svg)
![Flask](https://img.shields.io/badge/Flask-Web%20App-green.svg)
![scikit-learn](https://img.shields.io/badge/scikit--learn-ML-orange.svg)
![Docker](https://img.shields.io/badge/Docker-Containerized-blue.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

A production-ready, modular machine learning project that predicts wine quality based on physicochemical properties. This project demonstrates best practices in ML engineering with a complete pipeline from data ingestion to model deployment.

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Project Structure](#project-structure)
- [Installation](#installation)
- [Usage](#usage)
- [ML Pipeline Stages](#ml-pipeline-stages)
- [Model Details](#model-details)
- [API Endpoints](#api-endpoints)
- [Docker Deployment](#docker-deployment)
- [Configuration](#configuration)
- [License](#license)

## ğŸ¯ Overview

This project implements a complete end-to-end machine learning workflow for predicting wine quality scores. It uses the Wine Quality dataset and employs an ElasticNet regression model to predict quality ratings based on 11 physicochemical features.

### Input Features

| Feature | Description |
|---------|-------------|
| Fixed Acidity | Tartaric acid content (g/dmÂ³) |
| Volatile Acidity | Acetic acid content (g/dmÂ³) |
| Citric Acid | Citric acid content (g/dmÂ³) |
| Residual Sugar | Remaining sugar after fermentation (g/dmÂ³) |
| Chlorides | Sodium chloride content (g/dmÂ³) |
| Free Sulfur Dioxide | Free SOâ‚‚ content (mg/dmÂ³) |
| Total Sulfur Dioxide | Total SOâ‚‚ content (mg/dmÂ³) |
| Density | Density of wine (g/cmÂ³) |
| pH | pH level |
| Sulphates | Potassium sulphate content (g/dmÂ³) |
| Alcohol | Alcohol percentage (% vol) |

## âœ¨ Features

- **Modular Architecture**: Clean separation of components, entities, pipelines, and utilities
- **Configuration-Driven**: YAML-based configuration for easy customization
- **Automated Pipelines**: End-to-end training and prediction pipelines
- **Data Validation**: Schema-based validation to ensure data quality
- **Flask Web App**: User-friendly web interface for predictions
- **Docker Support**: Containerized deployment for consistency
- **Logging**: Comprehensive logging for debugging and monitoring
- **Research Notebooks**: Jupyter notebooks for experimentation

## ğŸ“ Project Structure

```
End-to-End-ML-Project/
â”‚
â”œâ”€â”€ app.py                     # Flask web application
â”œâ”€â”€ main.py                    # Training pipeline orchestrator
â”œâ”€â”€ Dockerfile                 # Docker configuration
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ setup.py                   # Package setup
â”œâ”€â”€ params.yaml                # Model hyperparameters
â”œâ”€â”€ schema.yaml                # Data schema definition
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml            # Pipeline configurations
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/            # Core ML components
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py
â”‚   â”‚   â”œâ”€â”€ data_validation.py
â”‚   â”‚   â”œâ”€â”€ data_transformation.py
â”‚   â”‚   â”œâ”€â”€ model_trainer.py
â”‚   â”‚   â””â”€â”€ model_evaluation.py
â”‚   â”‚
â”‚   â”œâ”€â”€ pipelines/             # Training & prediction pipelines
â”‚   â”‚   â”œâ”€â”€ data_ingestion_pipeline.py
â”‚   â”‚   â”œâ”€â”€ data_validation_pipeline.py
â”‚   â”‚   â”œâ”€â”€ data_transformation_pipeline.py
â”‚   â”‚   â”œâ”€â”€ model_trainer_pipeline.py
â”‚   â”‚   â”œâ”€â”€ model_evaluation_pipeline.py
â”‚   â”‚   â””â”€â”€ prediction_pipeline.py
â”‚   â”‚
â”‚   â”œâ”€â”€ config/                # Configuration management
â”‚   â”‚   â””â”€â”€ configuration.py
â”‚   â”‚
â”‚   â”œâ”€â”€ entities/              # Data classes & entities
â”‚   â”‚   â””â”€â”€ config_entity.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                 # Utility functions
â”‚   â”‚   â””â”€â”€ common.py
â”‚   â”‚
â”‚   â”œâ”€â”€ logging/               # Logging configuration
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â””â”€â”€ constants/             # Project constants
â”‚       â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ artifacts/                 # Generated artifacts
â”‚   â”œâ”€â”€ data_ingestion/        # Downloaded & extracted data
â”‚   â”œâ”€â”€ data_validation/       # Validation status
â”‚   â”œâ”€â”€ data_transformation/   # Train/test splits
â”‚   â”œâ”€â”€ model_trainer/         # Trained model
â”‚   â””â”€â”€ model_evaluation/      # Evaluation metrics
â”‚
â”œâ”€â”€ research/                  # Jupyter notebooks for experimentation
â”‚   â”œâ”€â”€ 01_data_ingestion.ipynb
â”‚   â”œâ”€â”€ 02_data_validation.ipynb
â”‚   â”œâ”€â”€ 03_data_transformation.ipynb
â”‚   â”œâ”€â”€ 04_model_trainer.ipynb
â”‚   â””â”€â”€ 05_model_evaluation.ipynb
â”‚
â”œâ”€â”€ templates/                 # HTML templates for Flask
â”‚   â”œâ”€â”€ index.html
â”‚   â””â”€â”€ results.html
â”‚
â””â”€â”€ logs/                      # Application logs
```

## ğŸš€ Installation

### Prerequisites

- Python 3.10 or higher
- pip (Python package manager)
- Git

### Step 1: Clone the Repository

```bash
git clone https://github.com/LochanaLithira/End-to-End-ML-Project.git
cd End-to-End-ML-Project
```

### Step 2: Create Virtual Environment

```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
# On Windows:
.\venv\Scripts\activate

# On macOS/Linux:
source venv/bin/activate
```

### Step 3: Install Dependencies

```bash
pip install -r requirements.txt
```

## ğŸ’» Usage

### Training the Model

Run the complete training pipeline:

```bash
python main.py
```

This executes all pipeline stages:
1. Data Ingestion
2. Data Validation
3. Data Transformation
4. Model Training
5. Model Evaluation

### Starting the Web Application

```bash
python app.py
```

The application will be available at `http://localhost:5000`

### Making Predictions via Web Interface

1. Navigate to `http://localhost:5000`
2. Enter the wine's physicochemical properties
3. Click "Predict" to get the quality prediction

## ğŸ”„ ML Pipeline Stages

### 1. Data Ingestion
- Downloads the Wine Quality dataset from the source URL
- Extracts the ZIP file to the artifacts directory
- Saves raw data for subsequent processing

### 2. Data Validation
- Validates the dataset schema against predefined columns
- Checks data types and column presence
- Generates validation status report

### 3. Data Transformation
- Removes unnecessary columns (Id)
- Splits data into training (80%) and testing (20%) sets
- Saves processed datasets as CSV files

### 4. Model Training
- Trains an ElasticNet regression model
- Uses hyperparameters from `params.yaml`
- Saves the trained model using joblib

### 5. Model Evaluation
- Evaluates model performance on test data
- Calculates metrics: RMSE, MAE, RÂ² Score
- Saves metrics to JSON file

## ğŸ¤– Model Details

### Algorithm: ElasticNet Regression

ElasticNet combines L1 (Lasso) and L2 (Ridge) regularization, providing a balance between feature selection and coefficient shrinkage.

### Hyperparameters

| Parameter | Value | Description |
|-----------|-------|-------------|
| alpha | 0.2 | Regularization strength |
| l1_ratio | 0.1 | Mix ratio between L1 and L2 |
| random_state | 42 | Random seed for reproducibility |

### Model Performance

| Metric | Value |
|--------|-------|
| RMSE | 0.622 |
| MAE | 0.494 |
| RÂ² Score | 0.305 |

## ğŸŒ API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Home page with prediction form |
| `/train` | GET | Trigger model training |
| `/predict` | POST | Submit features for prediction |

## ğŸ³ Docker Deployment

### Build the Docker Image

```bash
docker build -t wine-quality-prediction .
```

### Run the Container

```bash
docker run -p 5000:5000 wine-quality-prediction
```

Access the application at `http://localhost:5000`

## âš™ï¸ Configuration

### config/config.yaml
Contains paths and configurations for all pipeline stages:
- Data ingestion URLs and directories
- Data validation paths
- Model training and evaluation paths

### params.yaml
Contains model hyperparameters:
```yaml
ElasticNet:
  alpha: 0.2
  l1_ratio: 0.1
  random_state: 42
```

### schema.yaml
Defines the expected data schema:
- Column names and data types
- Target column specification

## ğŸ“Š Research Notebooks

The `research/` directory contains Jupyter notebooks for each pipeline stage:

| Notebook | Description |
|----------|-------------|
| `01_data_ingestion.ipynb` | Data downloading and extraction |
| `02_data_validation.ipynb` | Schema validation experiments |
| `03_data_transformation.ipynb` | Data preprocessing and splitting |
| `04_model_trainer.ipynb` | Model training experiments |
| `05_model_evaluation.ipynb` | Model evaluation and metrics |
| `experiments.ipynb` | General experimentation |

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¤ Author

**LochanaLithira**

---

<p align="center">
  Made with â¤ï¸ for Machine Learning Engineering
</p>
